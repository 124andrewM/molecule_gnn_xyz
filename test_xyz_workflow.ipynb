{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMre4PYLaUSRI3q8zouHHB/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/124andrewM/molecule_gnn_xyz/blob/main/test_xyz_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Molecule XYZ"
      ],
      "metadata": {
        "id": "jBPFHDYfRNwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Purpose: A basic workflow using the Keras API to test data input-output.\n",
        "\n",
        "Note: you will need to transfer the sample data which is comma seperated into your Google Drive. Adjust the file paths and folders names as required below.\n",
        "\n",
        "## Data Process\n",
        "- Data is first parsed by taking the atoms and a NumPy array of the coordinates.\n",
        "- Atoms are one-hot encoded for numerical input.\n",
        "- Each atom gets a one-hot encoding and it's xyz coordinates.\n",
        "- Building very basic adjacency matrices using a simple threshold value for whether atoms are connected.\n",
        "- Padding the molecule graphs with 0's.\n",
        "- Using a binary mask (0 = padding, 1 = real atom) for tracking the padded nodes.\n",
        "- Batching using tf (TensorFlow Dataset).\n",
        "\n",
        "## Model\n",
        "- The model uses GCN layers followed by masked average pooling (pooling but ignoring the padded atoms), then a dense layer to give us a binary classification using a sigmoid activation function."
      ],
      "metadata": {
        "id": "ifYrSFvkRPds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QuQvifm0QpPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92ade98-54c2-49ad-ea6f-35d9fc9735b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xg5eufG81R5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "B36Vyu_tRMQK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# An easy way to toggle print statements\n",
        "VERBOSE = True"
      ],
      "metadata": {
        "id": "WE8QGqysVZyU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stable_data_path = '/content/drive/MyDrive/sample-data-xyz/stable'\n",
        "unstable_data_path = '/content/drive/MyDrive/sample-data-xyz/unstable'"
      ],
      "metadata": {
        "id": "m1OFfE-Cjyp5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the chars into a numerical form."
      ],
      "metadata": {
        "id": "eaqXEoVxAupm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qm9_atoms = ['H', 'C', 'N', 'O', 'F']\n",
        "encoder = OneHotEncoder(categories=[qm9_atoms], sparse_output=False, handle_unknown='ignore')\n",
        "encoder.fit(np.array(qm9_atoms).reshape(-1, 1))"
      ],
      "metadata": {
        "id": "P_CKriZQt--_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: parse_comma_files\n",
        "- Just extracting the contents of the files, comma works better as a safety net."
      ],
      "metadata": {
        "id": "s1rL6SnPpbOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_comma_files(file_path):\n",
        "  atoms, coords = [], []\n",
        "  with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "      single_atom = line.strip().split(',')\n",
        "      if len(single_atom) == 4:\n",
        "        atoms.append(single_atom[0])\n",
        "        coords.append([float(val) for val in single_atom[1:]])\n",
        "  return atoms, np.array(coords)"
      ],
      "metadata": {
        "id": "XkJwd4HlRd9g"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: dense_adj\n",
        "- 1.0 is a completely random value to select which atoms are connected. Function definetly needs changing."
      ],
      "metadata": {
        "id": "VHt4boAH4gw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_adj(coords):\n",
        "    # linalg (linear algebra from NumPy)\n",
        "    # Computes pairwise distances between atoms using Euclidean norm\n",
        "    dists = np.linalg.norm(coords[:, None] - coords[None, :], axis=-1)\n",
        "    adj = ((dists < 1.0) & (dists > 0)).astype(np.float32)\n",
        "    return adj"
      ],
      "metadata": {
        "id": "9LceujXW24G3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: pad_array\n",
        "- Padding to the largest molecule size"
      ],
      "metadata": {
        "id": "mMI0swzouIGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding because Spektrals disjoint data mode was a nightmare.\n",
        "def pad_array(arr, new_shape):\n",
        "    p_val = 0.0\n",
        "    padded = np.full(new_shape, p_val, dtype=arr.dtype)\n",
        "    padded[:arr.shape[0], :arr.shape[1]] = arr\n",
        "    return padded"
      ],
      "metadata": {
        "id": "fknK1Y3oUm7S"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: prepare_data"
      ],
      "metadata": {
        "id": "zWDrsWmLkqzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(stable_dir, unstable_dir):\n",
        "    node_list, adj_list, mask_list, label_list = [], [], [], []\n",
        "    all_files = [] # Temp list to collect all files and labels\n",
        "\n",
        "    # Iterate over both stable and unstable folders\n",
        "    for label, folder in [(1, stable_dir), (0, unstable_dir)]:\n",
        "        for file_name in os.listdir(folder):\n",
        "            file_path = os.path.join(folder, file_name)\n",
        "            all_files.append((file_path, label))\n",
        "\n",
        "    max_nodes = 0 # This will tell us how much padding to add\n",
        "    temp_graphs = [] # Purely temp storage for the second loop\n",
        "\n",
        "    # Go through each file-label pair and build a temp dataset\n",
        "    for file_path, label in all_files:\n",
        "        # Parse atom labels and 3D coords\n",
        "        atoms, coords = parse_comma_files(file_path)\n",
        "        # Save as a single data set\n",
        "        temp_graphs.append((atoms, coords, label))\n",
        "        # Adjust max_nodes if needed\n",
        "        max_nodes = max(max_nodes, len(atoms))\n",
        "\n",
        "    # Process each molecule\n",
        "    for atoms, coords, label in temp_graphs:\n",
        "        shaped_atoms = np.array(atoms).reshape(-1, 1) # Reshape the atoms\n",
        "        encoded_atoms = encoder.transform(shaped_atoms).astype(np.float32) # Convert chars into one-hot encoded vector\n",
        "        e_atoms = np.concatenate([encoded_atoms, coords], axis=-1) # Shape the en as a single vector\n",
        "        num_real = e_atoms.shape[0] # Store the number of real nodes before padding\n",
        "\n",
        "        node_list.append(pad_array(e_atoms, (max_nodes, e_atoms.shape[1])))\n",
        "        adj_list.append(pad_array(dense_adj(coords), (max_nodes, max_nodes)))\n",
        "        label_list.append(np.array([label], dtype=np.float32))\n",
        "\n",
        "        mask = np.zeros((max_nodes,), dtype=np.float32) # Create a binary mask vector\n",
        "        mask[:num_real] = 1.0 # 1 is a real atom, otherwise it's padding\n",
        "        mask_list.append(mask)\n",
        "\n",
        "    return (\n",
        "        np.array(node_list),\n",
        "        np.array(adj_list),\n",
        "        np.array(mask_list),\n",
        "        np.array(label_list),\n",
        "        max_nodes\n",
        "    )"
      ],
      "metadata": {
        "id": "EqqvtsDKUqup"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: create_tf_ds\n",
        "- Creates a tf dataset and batches them"
      ],
      "metadata": {
        "id": "SPQpEw8ptV_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_ds(molecules, adj_arr, mask_arr, labels, batch_size=32, shuffle=True):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(((molecules, adj_arr, mask_arr), labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(molecules))\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "Ex6J1IY8UutZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: masked_avg_pooling\n",
        "- Custom pooling function to account for padding.\n",
        "- Essentially, compressing all node features into one vector for passing into the dense layer."
      ],
      "metadata": {
        "id": "HJyV9unptiSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_avg_pooling(node_embeddings, node_mask):\n",
        "    masked_embeddings = node_embeddings * tf.expand_dims(node_mask, axis=-1) # 0 out padded nodes\n",
        "    summed_features = tf.reduce_sum(masked_embeddings, axis=1) # sum over real nodes\n",
        "    count = tf.reduce_sum(node_mask, axis=1) # count the real nodes\n",
        "    return summed_features / tf.maximum(count, 1) # prevent division by zero"
      ],
      "metadata": {
        "id": "uz-glaKXthvN"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class GraphConvLayer\n",
        "- Basic template class for graph data.\n",
        "- Call takes two inputs: `node_features` and `adjacency`"
      ],
      "metadata": {
        "id": "gwOFo--8tz7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvLayer(layers.Layer):\n",
        "    def __init__(self, output_size, activation=None):\n",
        "        super().__init__()\n",
        "        self.output_size = output_size\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        num_features = input_shape[0][-1]\n",
        "\n",
        "        self.kernel = self.add_weight(shape=(num_features, self.output_size),\n",
        "                                      initializer='glorot_uniform',\n",
        "                                      name='kernel')\n",
        "        self.bias = self.add_weight(shape=(self.output_size,),\n",
        "                                    initializer='zeros',\n",
        "                                    name='bias')\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        node_features, adjacency = inputs\n",
        "        messages = tf.matmul(adjacency, node_features)\n",
        "        output = tf.matmul(messages, self.kernel) + self.bias\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "HrbjXVAktyg5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Data"
      ],
      "metadata": {
        "id": "fvkK7opTuaw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and process our data\n",
        "molecules, adj_arr, mask_arr, labels, max_nodes = prepare_data(stable_data_path, unstable_data_path)\n",
        "if VERBOSE:\n",
        "  print(\"Loaded\", molecules.shape[0], \"graphs, each padded to\", max_nodes, \"nodes\")"
      ],
      "metadata": {
        "id": "efexZAyhuCRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Datasets"
      ],
      "metadata": {
        "id": "zl4nQINQuixR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_molecules = molecules.shape[0]\n",
        "indices = np.arange(num_molecules)\n",
        "np.random.shuffle(indices)\n",
        "split = int(0.8 * num_molecules)\n",
        "train_idx, test_idx = indices[:split], indices[split:]\n",
        "\n",
        "m_train, adj_train, mask_train, label_train = molecules[train_idx], adj_arr[train_idx], mask_arr[train_idx], labels[train_idx]\n",
        "m_test, adj_test, mask_test, label_test = molecules[test_idx], adj_arr[test_idx], mask_arr[test_idx], labels[test_idx]\n",
        "\n",
        "train_ds = create_tf_ds(m_train, adj_train, mask_train, label_train, batch_size=32, shuffle=True)\n",
        "test_ds = create_tf_ds(m_test, adj_test, mask_test, label_test, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "ivfTqCkEUvTS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the model"
      ],
      "metadata": {
        "id": "B8mC8SW-unEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_mols = Input(shape=(max_nodes, molecules.shape[-1]), name=\"node_features\")\n",
        "input_adj = Input(shape=(max_nodes, max_nodes), name=\"adjacency\")\n",
        "input_mask = Input(shape=(max_nodes,), name=\"mask\")\n",
        "\n",
        "layer_1 = GraphConvLayer(32, activation='relu')([input_mols, input_adj])\n",
        "layer_2 = GraphConvLayer(32, activation='relu')([layer_1, input_adj])\n",
        "pool = layers.Lambda(lambda args: masked_avg_pooling(*args))([layer_2, input_mask])\n",
        "output = Dense(1, activation='sigmoid')(pool)\n",
        "model = Model(inputs=[input_mols, input_adj, input_mask], outputs=output)"
      ],
      "metadata": {
        "id": "aLuyHgrCU0x6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile the model"
      ],
      "metadata": {
        "id": "aZ4PsE7EvGcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(1e-3),\n",
        "              loss=BinaryCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "REMPRwzGvFce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "p6c_XkI8ur38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, epochs=30)"
      ],
      "metadata": {
        "id": "ds5cvZzYU8LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the model"
      ],
      "metadata": {
        "id": "MTijwcPqusdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_ds)\n",
        "preds = predictions.flatten()\n",
        "true = label_test.flatten()\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"Sample Num: {i+1}, Real Label: {int(true[i])}, Predicted Probability: {preds[i]:.4f}\")"
      ],
      "metadata": {
        "id": "IXH0hDzPFSBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Test Loss: \", loss)\n",
        "print(\"Test Accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "Ys9h80gkU9gC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}